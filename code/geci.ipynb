{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    " #coding:utf-8\n",
    "import sys\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import collections\n",
    "sys.path.append('D:\\bigdatahw\\Case contest\\data')            #增加搜索路径\n",
    "data = {'start':[], 'end':[],'clean_lyrics' : []}\n",
    "with open('alldata.csv', 'r',encoding='gbk') as f:\n",
    "    reader = csv.DictReader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        data['start'].append(row[\"start\"])\n",
    "        data['end'].append(row[\"end\"])\n",
    "        data['clean_lyrics'].append(row[\"clean_lyrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.Series(data) \n",
    "start=[line.split(\"_\")[0] for line in data.get('start') ]\n",
    "end=[line.split(\"_\")[0] for line in data.get('end') ]\n",
    "clean_lyrics=[line for line in data.get('clean_lyrics') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_2012=[]\n",
    "fashion_2013=[]\n",
    "fashion_2014=[]\n",
    "fashion_2015=[]\n",
    "fashion_2016=[]\n",
    "fashion_2017=[]\n",
    "fashion_2018=[]\n",
    "dictionary={}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fashion(a):\n",
    "    j=-1\n",
    "    d=[]\n",
    "    for i in start:\n",
    "        j=j+1 \n",
    "        if a==i :\n",
    "            d.extend(clean_lyrics[j].split())\n",
    "            if start[j]==end[j]:\n",
    "                continue\n",
    "        elif a==end[j]:\n",
    "            d.extend(clean_lyrics[j])\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_2012=fashion('2012')\n",
    "fashion_2013=fashion('2013')\n",
    "fashion_2014=fashion('2014')\n",
    "fashion_2015=fashion('2015')\n",
    "fashion_2016=fashion('2016')\n",
    "fashion_2017=fashion('2017')\n",
    "fashion_2018=fashion('2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['and' '1430']\n",
      " ['like' '1413']\n",
      " ['you' '1313']\n",
      " ['love' '1181']\n",
      " ['know' '1108']\n",
      " ['got' '1036']\n",
      " ['get' '965']\n",
      " ['let' '876']\n",
      " ['baby' '818']\n",
      " ['yeah' '743']]\n"
     ]
    }
   ],
   "source": [
    "#词频统计,转化成矩阵\n",
    "word_count = np.array(collections.Counter(fashion_2012).most_common())\n",
    "print (word_count[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csvfile = open('word_count_2012.csv','w') \n",
    "writer = csv.writer(csvfile)\n",
    "for row in word_count:\n",
    "    writer.writerow([row[0], row[1]])\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_count = np.array(collections.Counter(fashion_2013).most_common())\n",
    "csvfile = open('word_count_2013.csv','w') \n",
    "writer = csv.writer(csvfile)\n",
    "for row in word_count:\n",
    "    writer.writerow([row[0], row[1]])\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_count = np.array(collections.Counter(fashion_2014).most_common())\n",
    "csvfile = open('word_count_2014.csv','w') \n",
    "writer = csv.writer(csvfile)\n",
    "for row in word_count:\n",
    "    writer.writerow([row[0], row[1]])\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_count = np.array(collections.Counter(fashion_2015).most_common())\n",
    "csvfile = open('word_count_2015.csv','w') \n",
    "writer = csv.writer(csvfile)\n",
    "for row in word_count:\n",
    "    writer.writerow([row[0], row[1]])\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_count = np.array(collections.Counter(fashion_2016).most_common())\n",
    "csvfile = open('word_count_2016.csv','w') \n",
    "writer = csv.writer(csvfile)\n",
    "for row in word_count:\n",
    "    writer.writerow([row[0], row[1]])\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_count = np.array(collections.Counter(fashion_2017).most_common())\n",
    "csvfile = open('word_count_2017.csv','w') \n",
    "writer = csv.writer(csvfile)\n",
    "for row in word_count:\n",
    "    writer.writerow([row[0], row[1]])\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_count = np.array(collections.Counter(fashion_2018).most_common())\n",
    "csvfile = open('word_count_2018.csv','w') \n",
    "writer = csv.writer(csvfile)\n",
    "for row in word_count:\n",
    "    writer.writerow([row[0], row[1]])\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start=[line.split(\"_\")[0] for line in data.get('start') ]\n",
    "end=[line.split(\"_\")[0] for line in data.get('end') ]\n",
    "clean_lyrics=[line for line in data.get('clean_lyrics') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('D:\\bigdatahw\\Case contest\\data')            #增加搜索路径\n",
    "data = {'genre':[],'clean_lyrics' : []}\n",
    "with open('alldata.csv', 'r',encoding='gbk') as f:\n",
    "    reader = csv.DictReader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        data['genre'].append(row[\"genre\"])\n",
    "        data['clean_lyrics'].append(row[\"clean_lyrics\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre=[]\n",
    "for line in data.get('genre'):\n",
    "    if line=='R&amp;B':\n",
    "        line='R&B'\n",
    "    genre.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_lyrics=data.get('clean_lyrics')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genre_class(a):\n",
    "    j=-1\n",
    "    d=[]\n",
    "    for i in genre:\n",
    "        j=j+1 \n",
    "        if a==i :\n",
    "            d.extend(clean_lyrics[j].split())\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pop = genre_class('Pop')\n",
    "Rap_Hip_Hop = genre_class('Rap/Hip Hop')\n",
    "Country=genre_class('Country')\n",
    "R_B=genre_class('R&B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = np.array(collections.Counter(Rap_Hip_Hop).most_common())\n",
    "csvfile = open('word_count_Rap.csv','w') \n",
    "writer = csv.writer(csvfile)\n",
    "for row in word_count:\n",
    "    writer.writerow([row[0], row[1]])\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_count = np.array(collections.Counter(Country).most_common())\n",
    "csvfile = open('word_count_Country.csv','w') \n",
    "writer = csv.writer(csvfile)\n",
    "for row in word_count:\n",
    "    writer.writerow([row[0], row[1]])\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_count = np.array(collections.Counter(R_B).most_common())\n",
    "csvfile = open('word_count_R_B.csv','w') \n",
    "writer = csv.writer(csvfile)\n",
    "for row in word_count:\n",
    "    writer.writerow([row[0], row[1]])\n",
    "csvfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
